{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc-3DH1eGKDF",
        "outputId": "92b8146e-8a16-44ec-f90f-0059d42c2049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BCE loss(Tumor Growth real data)\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sin = torch.sin\n",
        "cos = torch.cos\n",
        "exp = torch.exp\n",
        "pi = torch.pi\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "epochs = 80000  # iterations\n",
        "h = 100  # Test point grid density\n",
        "N = 2000  # interior points\n",
        "N1 = 100  # boundary points\n",
        "N2 = 200  # data points\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    np.random.seed(seed)\n",
        "\n",
        "setup_seed(123456)\n",
        "\n",
        "def gen_testdata():\n",
        "    data = np.load(\"/content/drive/MyDrive/2D_RS_Real_1_t.npz\")\n",
        "\n",
        "\n",
        "    t, x, y, usol = data[\"t\"], data[\"x\"], data[\"y\"], data[\"u_sol\"]\n",
        "    xx, yy, tt = np.meshgrid(x, y, t)\n",
        "    X = np.vstack((np.ravel(xx), np.ravel(yy), np.ravel(tt))).T\n",
        "    z = usol.flatten()[:, None]\n",
        "    return X, z\n",
        "\n",
        "def l2_relative_error(z_true, z_pred):\n",
        "    return np.linalg.norm(z_true - z_pred) / np.linalg.norm(z_true)\n",
        "\n",
        "# Domain and Sampling\n",
        "def interior(n=N):\n",
        "    # sampling x∈[-3,3], y∈[-3,3], t∈[0,1]\n",
        "    x = torch.rand(n, 1)*6 - 3  # [-3,3]\n",
        "    y = torch.rand(n, 1)*6 - 3  # [-3,3]\n",
        "    t = torch.rand(n, 1)        # [0,1]\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True), y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def ini(n=N1):\n",
        "    # IC t=0\n",
        "    x = torch.rand(n, 1)*6 - 3\n",
        "    y = torch.rand(n, 1)*6 - 3\n",
        "    t = torch.zeros_like(x)\n",
        "    cond = torch.where(x**2+y**2<0.25, torch.full_like(x,1), torch.zeros_like(x))\n",
        "    return x.requires_grad_(True), y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def left(n=N1):\n",
        "    # BC u(-3,y,t)=0\n",
        "    t = torch.rand(n, 1)\n",
        "    x = -3 * torch.ones_like(t)\n",
        "    y = torch.rand(n, 1)*6 - 3\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True),y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def right(n=N1):\n",
        "    # BC u(3,y,t)=0\n",
        "    t = torch.rand(n, 1)\n",
        "    x = 3 * torch.ones_like(t)\n",
        "    y = torch.rand(n, 1)*6 - 3\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True),y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def up(n=N1):\n",
        "    # BC u(x,3,t)=0\n",
        "    t = torch.rand(n, 1)\n",
        "    y = 3 * torch.ones_like(t)\n",
        "    x = torch.rand(n, 1)*6 - 3\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True), y.requires_grad_(True),t.requires_grad_(True), cond\n",
        "\n",
        "def down(n=N1):\n",
        "    # BC u(x,-3,t)=0\n",
        "    t = torch.rand(n, 1)\n",
        "    y = -3 * torch.ones_like(t)\n",
        "    x = torch.rand(n, 1)*6 - 3\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True),y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def data_interior(n=N2):\n",
        "    # data\n",
        "    X, Y = gen_testdata()\n",
        "    ids = np.random.randint(X.shape[0], size=n)\n",
        "    xy_t = X[ids]\n",
        "    u_real = Y[ids]\n",
        "    xy_t = torch.from_numpy(xy_t)\n",
        "    cond = torch.from_numpy(u_real)\n",
        "    xy_t.requires_grad_(True)\n",
        "    return xy_t, cond\n",
        "\n",
        "# Neural Network\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(3, 64),  # input: x,y,t\n",
        "            torch.nn.Tanh(),\n",
        "            torch.nn.Linear(64, 64),\n",
        "            torch.nn.Tanh(),\n",
        "            torch.nn.Linear(64, 64),\n",
        "            torch.nn.Tanh(),\n",
        "            torch.nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.net(x)\n",
        "        u_val = torch.abs(features)\n",
        "        u_bce = torch.sigmoid(u_val)\n",
        "        return u_val, u_bce\n",
        "\n",
        "\n",
        "\n",
        "# Loss functions\n",
        "loss = torch.nn.MSELoss()\n",
        "bce_loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "def gradients(u, x, order=1):\n",
        "    if order == 1:\n",
        "        return torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u),\n",
        "                                 create_graph=True,\n",
        "                                 only_inputs=True)[0]\n",
        "    else:\n",
        "        return gradients(gradients(u, x), x, order=order-1)\n",
        "\n",
        "v = torch.nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "#v = torch.nn.Parameter(torch.tensor([1.9]), requires_grad=True)\n",
        "\n",
        "\n",
        "print('Initial v: ', v)\n",
        "\n",
        "def l_interior(u):\n",
        "    x, y, t, cond = interior()\n",
        "\n",
        "    u_val, _ = u(torch.cat([x, y, t], dim=1))\n",
        "    u_t = gradients(u_val, t, 1)\n",
        "    u_x = gradients(u_val, x, 1)\n",
        "    u_y = gradients(u_val, y, 1)\n",
        "    u_xx = gradients(u_val, x, 2)\n",
        "    u_yy = gradients(u_val, y, 2)\n",
        "\n",
        "    residual = u_t - 6*u_val*(u_x**2+u_y**2)-3*(u_val**2)*(u_xx + u_yy) - v*u_val\n",
        "    return loss(residual, cond)\n",
        "\n",
        "def l_ini(u):\n",
        "    # IC loss\n",
        "    x, y, t, cond = ini()\n",
        "    u_val, _ = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_left(u):\n",
        "    # BC loss\n",
        "    x, y, t, cond = left()\n",
        "    u_val, _ = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_right(u):\n",
        "    # BC loss\n",
        "    x, y, t, cond = right()\n",
        "    u_val, _ = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_up(u):\n",
        "    # BC loss\n",
        "    x, y, t, cond = up()\n",
        "    u_val, _ = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_down(u):\n",
        "    # BC loss\n",
        "    x, y, t, cond = down()\n",
        "    u_val, _ = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_data(u):\n",
        "    xyt, cond = data_interior()\n",
        "    _, u_bce = u(xyt)  # BCE\n",
        "    cond_binary = cond.clamp(0, 1)\n",
        "    return bce_loss_fn(u_bce, cond_binary)\n",
        "\n",
        "\n",
        "\n",
        "# Training\n",
        "\n",
        "u = MLP()\n",
        "opt = torch.optim.RAdam(list(u.parameters()) + [v], lr=1e-3)\n",
        "\n",
        "scheduler = StepLR(opt, step_size=1000, gamma=0.9)\n",
        "\n",
        "\n",
        "# record training\n",
        "L2_error = []\n",
        "v_values = []\n",
        "iterations = []\n",
        "\n",
        "# obtain training data\n",
        "xy_t, u_real = gen_testdata()\n",
        "xy_t = torch.from_numpy(xy_t)\n",
        "\n",
        "for i in range(epochs):\n",
        "    opt.zero_grad()\n",
        "    l_i = l_interior(u)\n",
        "    l_d = l_data(u)\n",
        "    l_initial = l_ini(u)\n",
        "    l_u = l_up(u)\n",
        "    l_dn = l_down(u)\n",
        "    l_l = l_left(u)\n",
        "    l_r = l_right(u)\n",
        "    # loss function\n",
        "    l = l_i + l_initial + l_dn + l_u + l_l + l_r + 5*l_data(u)\n",
        "    l.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(u.parameters(), 0.1)\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # record\n",
        "    v_values.append(v.item())\n",
        "    iterations.append(i+1)\n",
        "\n",
        "    if (i+1) % 1000 == 0 or i == 0:\n",
        "        print(f\"v grad: {v.grad}\")\n",
        "        u_pred, _ = u(xy_t)\n",
        "        error = l2_relative_error(u_real, u_pred.detach().numpy())\n",
        "        L2_error.append(error)\n",
        "        print(f\"Epoch {i+1}, L2 Relative Error: {error}, v: {v.item()}\")\n",
        "        print(f\"  loss: {l.item():.6f}\")\n",
        "\n",
        "\n",
        "print('Final v: ', v)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(iterations, v_values, 'b-', linewidth=2)\n",
        "plt.xlabel('number of iterations', fontsize=14)\n",
        "plt.ylabel('v', fontsize=14)\n",
        "plt.title('changes of v W.R.T iterations', fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "27btOoE_GPSk",
        "outputId": "7819d19c-3483-45e2-a393-acaa1a3c339b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial v:  Parameter containing:\n",
            "tensor([1.8645], requires_grad=True)\n",
            "v grad: tensor([0.0249])\n",
            "Epoch 1, L2 Relative Error: 0.9626379994378046, v: 1.8644338553948643\n",
            "  loss: 2.947928\n",
            "  Interior loss: 0.031442\n",
            "  Data loss: 0.714927\n",
            "  Initial loss: 0.032524\n",
            "  Up boundary loss: 0.010251\n",
            "  Down boundary loss: 0.002615\n",
            "  Left boundary loss: 0.016440\n",
            "  Right boundary loss: 0.006123\n",
            "v grad: tensor([0.0041])\n",
            "Epoch 1000, L2 Relative Error: 0.8146329585685446, v: 1.5186604872612275\n",
            "  loss: 2.750940\n",
            "  Interior loss: 0.007083\n",
            "  Data loss: 0.683938\n",
            "  Initial loss: 0.020036\n",
            "  Up boundary loss: 0.000597\n",
            "  Down boundary loss: 0.000961\n",
            "  Left boundary loss: 0.000892\n",
            "  Right boundary loss: 0.000299\n",
            "v grad: tensor([-0.0013])\n",
            "Epoch 2000, L2 Relative Error: 0.6490796382306054, v: 1.6909609495812148\n",
            "  loss: 2.671425\n",
            "  Interior loss: 0.017879\n",
            "  Data loss: 0.670358\n",
            "  Initial loss: 0.009051\n",
            "  Up boundary loss: 0.000354\n",
            "  Down boundary loss: 0.000295\n",
            "  Left boundary loss: 0.000051\n",
            "  Right boundary loss: 0.000221\n",
            "v grad: tensor([-0.0011])\n",
            "Epoch 3000, L2 Relative Error: 0.5862659575490913, v: 1.968092277196161\n",
            "  loss: 2.673844\n",
            "  Interior loss: 0.025670\n",
            "  Data loss: 0.659776\n",
            "  Initial loss: 0.011022\n",
            "  Up boundary loss: 0.000123\n",
            "  Down boundary loss: 0.000192\n",
            "  Left boundary loss: 0.000090\n",
            "  Right boundary loss: 0.000227\n",
            "v grad: tensor([-0.0017])\n",
            "Epoch 4000, L2 Relative Error: 0.563818864920474, v: 2.120825599734564\n",
            "  loss: 2.635388\n",
            "  Interior loss: 0.026629\n",
            "  Data loss: 0.650344\n",
            "  Initial loss: 0.006446\n",
            "  Up boundary loss: 0.000152\n",
            "  Down boundary loss: 0.000180\n",
            "  Left boundary loss: 0.000132\n",
            "  Right boundary loss: 0.000048\n",
            "v grad: tensor([0.0018])\n",
            "Epoch 5000, L2 Relative Error: 0.5639825854407362, v: 2.2190877368621167\n",
            "  loss: 2.675739\n",
            "  Interior loss: 0.028056\n",
            "  Data loss: 0.646213\n",
            "  Initial loss: 0.010395\n",
            "  Up boundary loss: 0.000079\n",
            "  Down boundary loss: 0.000075\n",
            "  Left boundary loss: 0.000057\n",
            "  Right boundary loss: 0.000070\n",
            "v grad: tensor([-0.0034])\n",
            "Epoch 6000, L2 Relative Error: 0.5330563792271436, v: 2.2841302909412695\n",
            "  loss: 2.692134\n",
            "  Interior loss: 0.037802\n",
            "  Data loss: 0.653324\n",
            "  Initial loss: 0.010452\n",
            "  Up boundary loss: 0.000166\n",
            "  Down boundary loss: 0.000032\n",
            "  Left boundary loss: 0.000061\n",
            "  Right boundary loss: 0.000072\n",
            "v grad: tensor([0.0016])\n",
            "Epoch 7000, L2 Relative Error: 0.5337433393704889, v: 2.3601695815057413\n",
            "  loss: 2.599453\n",
            "  Interior loss: 0.031189\n",
            "  Data loss: 0.647424\n",
            "  Initial loss: 0.011044\n",
            "  Up boundary loss: 0.000130\n",
            "  Down boundary loss: 0.000072\n",
            "  Left boundary loss: 0.000072\n",
            "  Right boundary loss: 0.000108\n",
            "v grad: tensor([-0.0018])\n",
            "Epoch 8000, L2 Relative Error: 0.527493952120512, v: 2.417431523711907\n",
            "  loss: 2.629825\n",
            "  Interior loss: 0.030748\n",
            "  Data loss: 0.650991\n",
            "  Initial loss: 0.011652\n",
            "  Up boundary loss: 0.000053\n",
            "  Down boundary loss: 0.000093\n",
            "  Left boundary loss: 0.000127\n",
            "  Right boundary loss: 0.000034\n",
            "v grad: tensor([-0.0006])\n",
            "Epoch 9000, L2 Relative Error: 0.520106409435638, v: 2.464573968192383\n",
            "  loss: 2.655843\n",
            "  Interior loss: 0.032605\n",
            "  Data loss: 0.644121\n",
            "  Initial loss: 0.013517\n",
            "  Up boundary loss: 0.000080\n",
            "  Down boundary loss: 0.000098\n",
            "  Left boundary loss: 0.000052\n",
            "  Right boundary loss: 0.000030\n",
            "v grad: tensor([0.0013])\n",
            "Epoch 10000, L2 Relative Error: 0.5160400807244317, v: 2.527132111500825\n",
            "  loss: 2.555026\n",
            "  Interior loss: 0.026313\n",
            "  Data loss: 0.639476\n",
            "  Initial loss: 0.006304\n",
            "  Up boundary loss: 0.000081\n",
            "  Down boundary loss: 0.000128\n",
            "  Left boundary loss: 0.000027\n",
            "  Right boundary loss: 0.000062\n",
            "v grad: tensor([-0.0051])\n",
            "Epoch 11000, L2 Relative Error: 0.5114911698683212, v: 2.572766384653128\n",
            "  loss: 2.629990\n",
            "  Interior loss: 0.029447\n",
            "  Data loss: 0.626611\n",
            "  Initial loss: 0.016170\n",
            "  Up boundary loss: 0.000082\n",
            "  Down boundary loss: 0.000084\n",
            "  Left boundary loss: 0.000111\n",
            "  Right boundary loss: 0.000070\n",
            "v grad: tensor([-0.0001])\n",
            "Epoch 12000, L2 Relative Error: 0.5165398472863623, v: 2.634454327995337\n",
            "  loss: 2.655798\n",
            "  Interior loss: 0.028603\n",
            "  Data loss: 0.638686\n",
            "  Initial loss: 0.007085\n",
            "  Up boundary loss: 0.000049\n",
            "  Down boundary loss: 0.000093\n",
            "  Left boundary loss: 0.000022\n",
            "  Right boundary loss: 0.000088\n",
            "v grad: tensor([-0.0023])\n",
            "Epoch 13000, L2 Relative Error: 0.5084008161363842, v: 2.6975166067325116\n",
            "  loss: 2.668834\n",
            "  Interior loss: 0.031490\n",
            "  Data loss: 0.648172\n",
            "  Initial loss: 0.004174\n",
            "  Up boundary loss: 0.000089\n",
            "  Down boundary loss: 0.000089\n",
            "  Left boundary loss: 0.000060\n",
            "  Right boundary loss: 0.000062\n",
            "v grad: tensor([-0.0030])\n",
            "Epoch 14000, L2 Relative Error: 0.5016976283295521, v: 2.726406760793342\n",
            "  loss: 2.591273\n",
            "  Interior loss: 0.028271\n",
            "  Data loss: 0.643939\n",
            "  Initial loss: 0.002713\n",
            "  Up boundary loss: 0.000299\n",
            "  Down boundary loss: 0.000116\n",
            "  Left boundary loss: 0.000096\n",
            "  Right boundary loss: 0.000045\n",
            "v grad: tensor([-8.1876e-05])\n",
            "Epoch 15000, L2 Relative Error: 0.49171509013816755, v: 2.7704303677738533\n",
            "  loss: 2.599189\n",
            "  Interior loss: 0.033666\n",
            "  Data loss: 0.643940\n",
            "  Initial loss: 0.004762\n",
            "  Up boundary loss: 0.000089\n",
            "  Down boundary loss: 0.000230\n",
            "  Left boundary loss: 0.000091\n",
            "  Right boundary loss: 0.000098\n",
            "v grad: tensor([0.0019])\n",
            "Epoch 16000, L2 Relative Error: 0.48944970223040846, v: 2.795175059252454\n",
            "  loss: 2.575422\n",
            "  Interior loss: 0.027127\n",
            "  Data loss: 0.639220\n",
            "  Initial loss: 0.007948\n",
            "  Up boundary loss: 0.000103\n",
            "  Down boundary loss: 0.000138\n",
            "  Left boundary loss: 0.000062\n",
            "  Right boundary loss: 0.000073\n",
            "v grad: tensor([-0.0026])\n",
            "Epoch 17000, L2 Relative Error: 0.493853516572212, v: 2.807513579566416\n",
            "  loss: 2.574051\n",
            "  Interior loss: 0.025907\n",
            "  Data loss: 0.642622\n",
            "  Initial loss: 0.011132\n",
            "  Up boundary loss: 0.000155\n",
            "  Down boundary loss: 0.000116\n",
            "  Left boundary loss: 0.000023\n",
            "  Right boundary loss: 0.000067\n",
            "v grad: tensor([0.0043])\n",
            "Epoch 18000, L2 Relative Error: 0.48827772389710744, v: 2.841634336633681\n",
            "  loss: 2.582266\n",
            "  Interior loss: 0.025031\n",
            "  Data loss: 0.641368\n",
            "  Initial loss: 0.008483\n",
            "  Up boundary loss: 0.000190\n",
            "  Down boundary loss: 0.000114\n",
            "  Left boundary loss: 0.000040\n",
            "  Right boundary loss: 0.000067\n",
            "v grad: tensor([0.0014])\n",
            "Epoch 19000, L2 Relative Error: 0.4819599117243848, v: 2.867067214737977\n",
            "  loss: 2.590291\n",
            "  Interior loss: 0.030357\n",
            "  Data loss: 0.643134\n",
            "  Initial loss: 0.001185\n",
            "  Up boundary loss: 0.000067\n",
            "  Down boundary loss: 0.000125\n",
            "  Left boundary loss: 0.000017\n",
            "  Right boundary loss: 0.000029\n",
            "v grad: tensor([0.0040])\n",
            "Epoch 20000, L2 Relative Error: 0.4854662250645892, v: 2.877253783057535\n",
            "  loss: 2.575238\n",
            "  Interior loss: 0.033219\n",
            "  Data loss: 0.640205\n",
            "  Initial loss: 0.003969\n",
            "  Up boundary loss: 0.000110\n",
            "  Down boundary loss: 0.000158\n",
            "  Left boundary loss: 0.000055\n",
            "  Right boundary loss: 0.000050\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-3878569445.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;31m# loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_initial\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_dn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_u\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_l\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_r\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_prims_common/wrappers.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mis_factory_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_factory_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}