{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t6FqLrsZuFk",
        "outputId": "36119e61-915c-414f-f4d6-5a176e9b5c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dxa_data\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sin = torch.sin\n",
        "cos = torch.cos\n",
        "exp = torch.exp\n",
        "pi = torch.pi\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "epochs = 60000  # 训练代数\n",
        "h = 100  # 测试点网格密度\n",
        "N = 2000  # 内点配置点数\n",
        "N1 = 100  # 边界点配置点数\n",
        "N2 = 200  # 数据点\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    np.random.seed(seed)\n",
        "\n",
        "setup_seed(123456)\n",
        "\n",
        "def gen_testdata():\n",
        "    # 修改为加载2D数据，格式应为 (x, y, t, exact)\n",
        "    # 这里假设数据已处理成适当格式\n",
        "\n",
        "    data = np.load(\"/content/drive/MyDrive/dxa_data_3_1.7.npz\")\n",
        "    #data = np.load(\"/content/drive/MyDrive/dxa_data_3_1.8.npz\")\n",
        "    #data = np.load(\"/content/drive/MyDrive/dxa_data_3_1.9.npz\")\n",
        "    #data = np.load(\"/content/drive/MyDrive/dxa_data_3_2.npz\")\n",
        "    #data = np.load(\"/content/drive/MyDrive/dxa_data_3_2.1.npz\")\n",
        "    #data = np.load(\"/content/drive/MyDrive/dxa_data_3_2.2.npz\")\n",
        "\n",
        "    t, x, y, usol = data[\"t\"], data[\"x\"], data[\"y\"], data[\"u_sol\"]  # 需要确保数据格式正确\n",
        "    xx, yy, tt = np.meshgrid(x, y, t)\n",
        "    X = np.vstack((np.ravel(xx), np.ravel(yy), np.ravel(tt))).T\n",
        "    z = usol.flatten()[:, None]\n",
        "    return X, z\n",
        "\n",
        "def l2_relative_error(z_true, z_pred):\n",
        "    return np.linalg.norm(z_true - z_pred) / np.linalg.norm(z_true)\n",
        "\n",
        "# Domain and Sampling (修改为3D采样)\n",
        "def interior(n=N):\n",
        "    # 内点采样 x∈[-3,3], y∈[-3,3], t∈[0,1]\n",
        "    x = torch.rand(n, 1)*6 - 3  # [-3,3]\n",
        "    y = torch.rand(n, 1)*6 - 3  # [-3,3]\n",
        "    t = torch.rand(n, 1)        # [0,1]\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True), y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def ini(n=N1):\n",
        "    # 初始条件 t=0\n",
        "    x = torch.rand(n, 1)*6 - 3\n",
        "    y = torch.rand(n, 1)*6 - 3\n",
        "    t = torch.zeros_like(x)\n",
        "    cond = torch.where(x**2+y**2<0.25, torch.full_like(x,0.5), torch.zeros_like(x))  # 示例条件\n",
        "    return x.requires_grad_(True), y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def left(n=N1):\n",
        "    # 边界 u(-3,y,t)=0\n",
        "    t = torch.rand(n, 1)\n",
        "    x = -3 * torch.ones_like(t)\n",
        "    y = torch.rand(n, 1)*6 - 3\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True),y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def right(n=N1):\n",
        "    # 边界 u(3,y,t)=0\n",
        "    t = torch.rand(n, 1)\n",
        "    x = 3 * torch.ones_like(t)\n",
        "    y = torch.rand(n, 1)*6 - 3\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True),y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def up(n=N1):\n",
        "    # 边界 u(x,3,t)=0\n",
        "    t = torch.rand(n, 1)\n",
        "    y = 3 * torch.ones_like(t)\n",
        "    x = torch.rand(n, 1)*6 - 3\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True), y.requires_grad_(True),t.requires_grad_(True), cond\n",
        "\n",
        "def down(n=N1):\n",
        "    # 边界 u(x,-3,t)=0\n",
        "    t = torch.rand(n, 1)\n",
        "    y = -3 * torch.ones_like(t)\n",
        "    x = torch.rand(n, 1)*6 - 3\n",
        "    cond = torch.zeros_like(t)\n",
        "    return x.requires_grad_(True),y.requires_grad_(True), t.requires_grad_(True), cond\n",
        "\n",
        "def data_interior(n=N2):\n",
        "    # 内点数据\n",
        "    X, Y = gen_testdata()\n",
        "    ids = np.random.randint(X.shape[0], size=n)\n",
        "    xy_t = X[ids]\n",
        "    u_real = Y[ids]\n",
        "    xy_t = torch.from_numpy(xy_t)\n",
        "    cond = torch.from_numpy(u_real)\n",
        "    xy_t.requires_grad_(True)\n",
        "    return xy_t, cond\n",
        "\n",
        "# Neural Network (输入维度改为3)\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(3, 64),  # 输入x,y,t\n",
        "            torch.nn.Tanh(),\n",
        "            torch.nn.Linear(64, 64),\n",
        "            torch.nn.Tanh(),\n",
        "            torch.nn.Linear(64, 64),\n",
        "            torch.nn.Tanh(),\n",
        "            torch.nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.net(x)\n",
        "        u_val = torch.abs(features)\n",
        "        return u_val\n",
        "\n",
        "\n",
        "# Loss functions\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "\n",
        "def gradients(u, x, order=1):\n",
        "    if order == 1:\n",
        "        return torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u),\n",
        "                                 create_graph=True,\n",
        "                                 only_inputs=True)[0]\n",
        "    else:\n",
        "        return gradients(gradients(u, x), x, order=order-1)\n",
        "\n",
        "v = torch.nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "#v = torch.nn.Parameter(torch.tensor([1.9]), requires_grad=True) ##33\n",
        "print('Initial v: ', v)\n",
        "\n",
        "def l_interior(u):\n",
        "    x, y, t, cond = interior()\n",
        "    inputs = torch.cat([x, y, t], dim=1)\n",
        "    u_val = u(inputs)  # 原始网络输出\n",
        "\n",
        "    # 计算缩放后的u'及其导数\n",
        "    u_prime = u_val * 1\n",
        "    u_t = gradients(u_prime, t, 1)\n",
        "    u_x = gradients(u_prime, x, 1)\n",
        "    u_y = gradients(u_prime, y, 1)\n",
        "    u_xx = gradients(u_prime, x, 2)\n",
        "    u_yy = gradients(u_prime, y, 2)\n",
        "\n",
        "\n",
        "    residual = u_t - 6*u_prime*(u_x**2+u_y**2)-3*(u_prime**2)*(u_xx + u_yy) - v*u_prime\n",
        "    return loss(residual, cond)\n",
        "\n",
        "def l_ini(u):\n",
        "    x, y, t, cond = ini()\n",
        "    u_val = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_left(u):\n",
        "    # 边界条件损失\n",
        "    x, y, t, cond = left()\n",
        "    u_val = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_right(u):\n",
        "    # 边界条件损失\n",
        "    x, y, t, cond = right()\n",
        "    u_val = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_up(u):\n",
        "    # 边界条件损失\n",
        "    x, y, t, cond = up()\n",
        "    u_val = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_down(u):\n",
        "    # 边界条件损失\n",
        "    x, y, t, cond = down()\n",
        "    u_val = u(torch.cat([x, y, t], dim=1))\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "def l_data(u):\n",
        "    xyt, cond = data_interior()\n",
        "    u_val = u(xyt)\n",
        "    return loss(u_val, cond)\n",
        "\n",
        "\n",
        "\n",
        "# Training\n",
        "#u = MLP()\n",
        "#opt = torch.optim.Adam(u.parameters(), lr=1e-3)\n",
        "u = MLP()\n",
        "opt = torch.optim.RAdam(list(u.parameters()) + [v], lr=1e-3)\n",
        "\n",
        "scheduler = StepLR(opt, step_size=1000, gamma=0.9)  # 对所有参数应用调度\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 记录训练过程\n",
        "L2_error = []\n",
        "v_values = []\n",
        "iterations = []\n",
        "\n",
        "# 获取测试数据\n",
        "xy_t, u_real = gen_testdata()\n",
        "xy_t = torch.from_numpy(xy_t)\n",
        "\n",
        "for i in range(epochs):\n",
        "    opt.zero_grad()\n",
        "    #opt1.zero_grad()\n",
        "    l_i = l_interior(u)\n",
        "    l_d = l_data(u)\n",
        "    l_initial = l_ini(u)\n",
        "    l_u = l_up(u)\n",
        "    l_dn = l_down(u)\n",
        "    l_l = l_left(u)\n",
        "    l_r = l_right(u)\n",
        "\n",
        "\n",
        "    # 计算各项损失\n",
        "    l = 10*l_i + l_initial + l_dn + l_u + l_l + l_r + 40*l_data(u)\n",
        "    l.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(u.parameters(), 0.1)\n",
        "\n",
        "    opt.step()\n",
        "    #opt1.step()\n",
        "    scheduler.step()\n",
        "    v.data.clamp_(min=1e-6)\n",
        "\n",
        "    # 记录参数\n",
        "    v_values.append(v.item())\n",
        "    iterations.append(i+1)\n",
        "\n",
        "    if (i+1) % 1000 == 0 or i == 0:\n",
        "        u_pred = u(xy_t)\n",
        "        error = l2_relative_error(u_real, u_pred.detach().numpy())\n",
        "        L2_error.append(error)\n",
        "        print(f\"Epoch {i+1}, L2相对误差: {error}, v: {v.item()}\")\n",
        "        print(f\"  Interior loss: {l_i.item():.6f}\")\n",
        "        print(f\"  Data loss: {l_d.item():.6f}\")\n",
        "        print(f\"  Initial loss: {l_initial.item():.6f}\")\n",
        "        print(f\"  Up boundary loss: {l_u.item():.6f}\")\n",
        "        print(f\"  Down boundary loss: {l_dn.item():.6f}\")\n",
        "        print(f\"  Left boundary loss: {l_l.item():.6f}\")\n",
        "        print(f\"  Right boundary loss: {l_r.item():.6f}\")\n",
        "        print(f\"  loss: {l.item():.6f}\")\n",
        "\n",
        "\n",
        "print('Final v: ', v)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(iterations, v_values, 'b-', linewidth=2)\n",
        "plt.xlabel('number of iterations', fontsize=14)\n",
        "plt.ylabel('v', fontsize=14)\n",
        "plt.title('changes of v W.R.T iterations', fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XJ12syhvOKpd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd0cede1-e487-4574-ac8c-8b309183cdf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial v:  Parameter containing:\n",
            "tensor([1.8645], requires_grad=True)\n",
            "Epoch 1, L2相对误差: 1.3757716663816213, v: 1.8642095136303796\n",
            "  Interior loss: 0.031442\n",
            "  Data loss: 0.007728\n",
            "  Initial loss: 0.011948\n",
            "  Up boundary loss: 0.010251\n",
            "  Down boundary loss: 0.002615\n",
            "  Left boundary loss: 0.016440\n",
            "  Right boundary loss: 0.006123\n",
            "  loss: 0.632939\n",
            "Epoch 1000, L2相对误差: 0.4075550584772359, v: 1.577906505004686\n",
            "  Interior loss: 0.001458\n",
            "  Data loss: 0.000595\n",
            "  Initial loss: 0.003971\n",
            "  Up boundary loss: 0.000057\n",
            "  Down boundary loss: 0.000113\n",
            "  Left boundary loss: 0.000187\n",
            "  Right boundary loss: 0.000082\n",
            "  loss: 0.052486\n",
            "Epoch 2000, L2相对误差: 0.3172550286395513, v: 1.36233018982723\n",
            "  Interior loss: 0.000997\n",
            "  Data loss: 0.000512\n",
            "  Initial loss: 0.001589\n",
            "  Up boundary loss: 0.000018\n",
            "  Down boundary loss: 0.000136\n",
            "  Left boundary loss: 0.000077\n",
            "  Right boundary loss: 0.000061\n",
            "  loss: 0.036588\n",
            "Epoch 3000, L2相对误差: 0.29755360311232787, v: 1.3221613970985047\n",
            "  Interior loss: 0.001168\n",
            "  Data loss: 0.000308\n",
            "  Initial loss: 0.001951\n",
            "  Up boundary loss: 0.000154\n",
            "  Down boundary loss: 0.000074\n",
            "  Left boundary loss: 0.000052\n",
            "  Right boundary loss: 0.000061\n",
            "  loss: 0.027194\n",
            "Epoch 4000, L2相对误差: 0.25457483537932785, v: 1.3337090148772122\n",
            "  Interior loss: 0.000866\n",
            "  Data loss: 0.000517\n",
            "  Initial loss: 0.001338\n",
            "  Up boundary loss: 0.000009\n",
            "  Down boundary loss: 0.000033\n",
            "  Left boundary loss: 0.000059\n",
            "  Right boundary loss: 0.000027\n",
            "  loss: 0.020177\n",
            "Epoch 5000, L2相对误差: 0.22035884040783646, v: 1.3628155354995852\n",
            "  Interior loss: 0.000715\n",
            "  Data loss: 0.000190\n",
            "  Initial loss: 0.002353\n",
            "  Up boundary loss: 0.000011\n",
            "  Down boundary loss: 0.000013\n",
            "  Left boundary loss: 0.000037\n",
            "  Right boundary loss: 0.000046\n",
            "  loss: 0.021913\n",
            "Epoch 6000, L2相对误差: 0.18127699450850016, v: 1.3906843229304455\n",
            "  Interior loss: 0.001086\n",
            "  Data loss: 0.000164\n",
            "  Initial loss: 0.001920\n",
            "  Up boundary loss: 0.000009\n",
            "  Down boundary loss: 0.000062\n",
            "  Left boundary loss: 0.000014\n",
            "  Right boundary loss: 0.000024\n",
            "  loss: 0.020620\n",
            "Epoch 7000, L2相对误差: 0.18558367196924513, v: 1.4204888764139632\n",
            "  Interior loss: 0.000627\n",
            "  Data loss: 0.000167\n",
            "  Initial loss: 0.002422\n",
            "  Up boundary loss: 0.000055\n",
            "  Down boundary loss: 0.000051\n",
            "  Left boundary loss: 0.000026\n",
            "  Right boundary loss: 0.000021\n",
            "  loss: 0.017350\n",
            "Epoch 8000, L2相对误差: 0.2001084628278842, v: 1.458315338066347\n",
            "  Interior loss: 0.000571\n",
            "  Data loss: 0.000158\n",
            "  Initial loss: 0.002329\n",
            "  Up boundary loss: 0.000008\n",
            "  Down boundary loss: 0.000015\n",
            "  Left boundary loss: 0.000007\n",
            "  Right boundary loss: 0.000009\n",
            "  loss: 0.014244\n",
            "Epoch 9000, L2相对误差: 0.16307268649585607, v: 1.4825445090191505\n",
            "  Interior loss: 0.000537\n",
            "  Data loss: 0.000149\n",
            "  Initial loss: 0.002740\n",
            "  Up boundary loss: 0.000012\n",
            "  Down boundary loss: 0.000008\n",
            "  Left boundary loss: 0.000011\n",
            "  Right boundary loss: 0.000015\n",
            "  loss: 0.013212\n",
            "Epoch 10000, L2相对误差: 0.14897039969813045, v: 1.5154857695952144\n",
            "  Interior loss: 0.000543\n",
            "  Data loss: 0.000079\n",
            "  Initial loss: 0.001125\n",
            "  Up boundary loss: 0.000023\n",
            "  Down boundary loss: 0.000017\n",
            "  Left boundary loss: 0.000008\n",
            "  Right boundary loss: 0.000013\n",
            "  loss: 0.012837\n",
            "Epoch 11000, L2相对误差: 0.1516714198771112, v: 1.5257801034591512\n",
            "  Interior loss: 0.000566\n",
            "  Data loss: 0.000124\n",
            "  Initial loss: 0.003294\n",
            "  Up boundary loss: 0.000011\n",
            "  Down boundary loss: 0.000007\n",
            "  Left boundary loss: 0.000003\n",
            "  Right boundary loss: 0.000011\n",
            "  loss: 0.013485\n",
            "Epoch 12000, L2相对误差: 0.14406005123333573, v: 1.5531848791246294\n",
            "  Interior loss: 0.000416\n",
            "  Data loss: 0.000046\n",
            "  Initial loss: 0.001458\n",
            "  Up boundary loss: 0.000005\n",
            "  Down boundary loss: 0.000007\n",
            "  Left boundary loss: 0.000005\n",
            "  Right boundary loss: 0.000007\n",
            "  loss: 0.010329\n",
            "Epoch 13000, L2相对误差: 0.12605798476048877, v: 1.5701235734418797\n",
            "  Interior loss: 0.000441\n",
            "  Data loss: 0.000059\n",
            "  Initial loss: 0.001264\n",
            "  Up boundary loss: 0.000004\n",
            "  Down boundary loss: 0.000007\n",
            "  Left boundary loss: 0.000005\n",
            "  Right boundary loss: 0.000010\n",
            "  loss: 0.010510\n",
            "Epoch 14000, L2相对误差: 0.13631900269746028, v: 1.5736819502586765\n",
            "  Interior loss: 0.000479\n",
            "  Data loss: 0.000107\n",
            "  Initial loss: 0.000487\n",
            "  Up boundary loss: 0.000003\n",
            "  Down boundary loss: 0.000008\n",
            "  Left boundary loss: 0.000001\n",
            "  Right boundary loss: 0.000018\n",
            "  loss: 0.008123\n",
            "Epoch 15000, L2相对误差: 0.12375549334462087, v: 1.5871988259119143\n",
            "  Interior loss: 0.000442\n",
            "  Data loss: 0.000062\n",
            "  Initial loss: 0.000955\n",
            "  Up boundary loss: 0.000003\n",
            "  Down boundary loss: 0.000007\n",
            "  Left boundary loss: 0.000002\n",
            "  Right boundary loss: 0.000004\n",
            "  loss: 0.008947\n",
            "Epoch 16000, L2相对误差: 0.127697061645988, v: 1.5978112837413516\n",
            "  Interior loss: 0.000445\n",
            "  Data loss: 0.000045\n",
            "  Initial loss: 0.002105\n",
            "  Up boundary loss: 0.000008\n",
            "  Down boundary loss: 0.000008\n",
            "  Left boundary loss: 0.000002\n",
            "  Right boundary loss: 0.000006\n",
            "  loss: 0.010504\n",
            "Epoch 17000, L2相对误差: 0.12459852130294317, v: 1.6029631550941899\n",
            "  Interior loss: 0.000440\n",
            "  Data loss: 0.000051\n",
            "  Initial loss: 0.002246\n",
            "  Up boundary loss: 0.000005\n",
            "  Down boundary loss: 0.000006\n",
            "  Left boundary loss: 0.000009\n",
            "  Right boundary loss: 0.000007\n",
            "  loss: 0.010437\n",
            "Epoch 18000, L2相对误差: 0.12320544765467566, v: 1.6142164902380611\n",
            "  Interior loss: 0.000389\n",
            "  Data loss: 0.000084\n",
            "  Initial loss: 0.001739\n",
            "  Up boundary loss: 0.000006\n",
            "  Down boundary loss: 0.000005\n",
            "  Left boundary loss: 0.000002\n",
            "  Right boundary loss: 0.000006\n",
            "  loss: 0.009730\n",
            "Epoch 19000, L2相对误差: 0.12302023641680047, v: 1.6243938688239206\n",
            "  Interior loss: 0.000497\n",
            "  Data loss: 0.000128\n",
            "  Initial loss: 0.000452\n",
            "  Up boundary loss: 0.000004\n",
            "  Down boundary loss: 0.000013\n",
            "  Left boundary loss: 0.000005\n",
            "  Right boundary loss: 0.000004\n",
            "  loss: 0.008152\n",
            "Epoch 20000, L2相对误差: 0.11483470315143982, v: 1.628029419115829\n",
            "  Interior loss: 0.000379\n",
            "  Data loss: 0.000067\n",
            "  Initial loss: 0.000882\n",
            "  Up boundary loss: 0.000006\n",
            "  Down boundary loss: 0.000004\n",
            "  Left boundary loss: 0.000004\n",
            "  Right boundary loss: 0.000008\n",
            "  loss: 0.008835\n",
            "Epoch 21000, L2相对误差: 0.12311815030963599, v: 1.6381814739425777\n",
            "  Interior loss: 0.000331\n",
            "  Data loss: 0.000105\n",
            "  Initial loss: 0.001909\n",
            "  Up boundary loss: 0.000004\n",
            "  Down boundary loss: 0.000005\n",
            "  Left boundary loss: 0.000002\n",
            "  Right boundary loss: 0.000008\n",
            "  loss: 0.006530\n",
            "Epoch 22000, L2相对误差: 0.11744762491809417, v: 1.6389396970222128\n",
            "  Interior loss: 0.000376\n",
            "  Data loss: 0.000034\n",
            "  Initial loss: 0.002276\n",
            "  Up boundary loss: 0.000003\n",
            "  Down boundary loss: 0.000003\n",
            "  Left boundary loss: 0.000002\n",
            "  Right boundary loss: 0.000004\n",
            "  loss: 0.009633\n",
            "Epoch 23000, L2相对误差: 0.11575914950967951, v: 1.6449470582004257\n",
            "  Interior loss: 0.000282\n",
            "  Data loss: 0.000108\n",
            "  Initial loss: 0.001239\n",
            "  Up boundary loss: 0.000002\n",
            "  Down boundary loss: 0.000006\n",
            "  Left boundary loss: 0.000003\n",
            "  Right boundary loss: 0.000004\n",
            "  loss: 0.007218\n",
            "Epoch 24000, L2相对误差: 0.11447221263355307, v: 1.648613396890774\n",
            "  Interior loss: 0.000348\n",
            "  Data loss: 0.000058\n",
            "  Initial loss: 0.002784\n",
            "  Up boundary loss: 0.000002\n",
            "  Down boundary loss: 0.000003\n",
            "  Left boundary loss: 0.000002\n",
            "  Right boundary loss: 0.000004\n",
            "  loss: 0.007848\n",
            "Epoch 25000, L2相对误差: 0.11298618217223944, v: 1.6581263013013794\n",
            "  Interior loss: 0.000430\n",
            "  Data loss: 0.000064\n",
            "  Initial loss: 0.002213\n",
            "  Up boundary loss: 0.000003\n",
            "  Down boundary loss: 0.000003\n",
            "  Left boundary loss: 0.000002\n",
            "  Right boundary loss: 0.000004\n",
            "  loss: 0.010357\n",
            "Epoch 26000, L2相对误差: 0.1127390202421481, v: 1.657992867208531\n",
            "  Interior loss: 0.000384\n",
            "  Data loss: 0.000059\n",
            "  Initial loss: 0.001188\n",
            "  Up boundary loss: 0.000002\n",
            "  Down boundary loss: 0.000005\n",
            "  Left boundary loss: 0.000002\n",
            "  Right boundary loss: 0.000003\n",
            "  loss: 0.009000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-3693993030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;31m# 计算各项损失\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_initial\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_dn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_u\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_l\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_r\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ 0.1*loss_v_penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;31m#print(\"v的梯度:\", v.grad.mean().item())   # 检查梯度是否与u_val同量级\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}